{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# KAGGLE-LIKE CHALLENGE\n",
    "On vous propose ici de tester tout ce que vous avez appris sur le machine learning supervisé, dans le but de faire un modèle de prédiction sur des données fournies, à la manière des compétitions Kaggle.\n",
    "\n",
    "**Déroulement d'un challenge Kaggle**\n",
    "- Kaggle vous envoie toujours deux datasets :\n",
    "  - un fichier data_train.csv qui contient des données correspondant aux variables X, et au label Y à prédire. Utilisez ce fichier pour entraîner vos modèles comme d'habitude.\n",
    "  - un fichier data_test.csv, qui contient les données X au même format que dans data_train.csv, mais cette fois les labels sont cachés. Votre but est de faire des prédictions sur ces données et de renvoyer ces prédictions à Kaggle, pour qu'ils évaluent votre modèle de manière indépendante\n",
    "- Kaggle compare vos prédictions aux vrais labels et propose un leaderboard (équipes classées en fonction de leur score)\n",
    "- Kaggle vous annonce à l'avance quelle métrique va être utilisée pour évaluer les modèles : veillez à utiliser la même métrique pour évaluer les performances de vos modèles\n",
    "\n",
    "**Prédiction de conversion**\n",
    "\n",
    "Ici, on vous propose d'essayer de créer le meilleur modèle pour prédire des conversions en fonction de différentes variables explicatives. Vos modèles seront évalués à l'aide du f1-score.\n",
    "\n",
    "*Inspirez-vous du template ci-dessous pour la lecture des fichiers, la structure à suivre, et l'écriture des prédictions finales.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "# Read file with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Set with labels (our train+test) : (284580, 6)\n"
    }
   ],
   "source": [
    "df = pd.read_csv('conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['age_page'] = df['age'] * df['total_pages_visited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM0feCss5sLZ"
   },
   "outputs": [],
   "source": [
    "# Don't forget to compute statistics and visualize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "# Make your model (as always)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPh1qPTf3wZU"
   },
   "source": [
    "## Choose variables to use in the model, and create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------\nLooking for outliers in  age\nFound 1017 outliers\nDropping outliers...\nDone.\nNumber of lines remaining in dataset :  283563\n\n"
    }
   ],
   "source": [
    "features_list_n = [\"age\"]\n",
    "\n",
    "for f in features_list_n:\n",
    "    print('------------')\n",
    "    print('Looking for outliers in ', f)\n",
    "    mu = df[f].mean()\n",
    "    sigma = df[f].std()\n",
    "    min_val = mu - 3*sigma\n",
    "    max_val = mu + 3*sigma\n",
    "    is_outlier = (df[f]<min_val) | (df[f]>max_val)\n",
    "    \n",
    "    if is_outlier.any():\n",
    "        print('Found {} outliers'.format(is_outlier.sum()))\n",
    "        print('Dropping outliers...')\n",
    "        df = df.loc[~is_outlier,:]\n",
    "        print('Done.')\n",
    "        print('Number of lines remaining in dataset : ', df.shape[0])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjEHMGoY3kMB"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Separating labels from features...\n...Done.\n\ny : \n0    0\n1    0\n2    1\n3    0\n4    0\nName: converted, dtype: int64\n\nX :\n   country  age  new_user  source  total_pages_visited\n0    China   22         1  Direct                    2\n1       UK   21         1     Ads                    3\n2  Germany   20         0     Seo                   14\n3       US   23         1     Seo                    3\n4       US   28         1  Direct                    3\n"
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "features_list = [\"country\", \"age\", \"new_user\", \"source\", \"total_pages_visited\"]\n",
    "target_variable = \"converted\"\n",
    "\n",
    "X = df.loc[:,features_list]\n",
    "Y = df.loc[:,target_variable]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print('y : ')\n",
    "print(Y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found numeric features  ['age', 'new_user', 'total_pages_visited']  at positions  [1, 2, 4]\nFound categorical features  ['country', 'source']  at positions  [0, 3]\n"
    }
   ],
   "source": [
    "# Search categorical features and numeric features\n",
    "\n",
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "  if ('float' in str(t)) or ('int' in str(t)) :\n",
    "    numeric_features.append(i)\n",
    "    numeric_indices.append(idx)\n",
    "  else :\n",
    "    categorical_features.append(i)\n",
    "    categorical_indices.append(idx)\n",
    "\n",
    "  idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dividing into train and test sets...\n...Done.\n\n"
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "vVu0eXQD4xVc",
    "outputId": "83a5f553-f50d-44dc-d12a-6cb21e74e4d7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Convert pandas DataFrames to numpy arrays...\n...Done\n[['China' 46 1 'Seo' 2]\n ['US' 29 1 'Direct' 6]\n ['China' 39 1 'Direct' 6]\n ['China' 34 0 'Ads' 6]\n ['US' 23 0 'Ads' 20]]\n[['China' 23 1 'Ads' 4]\n ['China' 30 0 'Direct' 13]]\n\n[0 0 0 0 1]\n[0 0]\n"
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b_aU7ij7K3Q"
   },
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_9bEZ5bn7I5Z",
    "outputId": "ad5c8f97-2d25-4827-f1ee-43c665a97fa0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Encoding categorical features and standardizing numerical features...\n\n[['China' 46 1 'Seo' 2]\n ['US' 29 1 'Direct' 6]\n ['China' 39 1 'Direct' 6]\n ['China' 34 0 'Ads' 6]\n ['US' 23 0 'Ads' 20]]\n\n[['China' 23 1 'Ads' 4]\n ['China' 30 0 'Direct' 13]\n ['US' 32 1 'Seo' 1]\n ['US' 27 1 'Ads' 3]\n ['UK' 25 1 'Seo' 5]]\n...Done\n[[ 1.91207418  0.67836596 -0.85951933  0.          0.          0.\n   0.          1.        ]\n [-0.18468574  0.67836596  0.33660037  0.          0.          1.\n   1.          0.        ]\n [ 1.04870245  0.67836596  0.33660037  0.          0.          0.\n   1.          0.        ]\n [ 0.43200836 -1.47413057  0.33660037  0.          0.          0.\n   0.          0.        ]\n [-0.92471865 -1.47413057  4.52301931  0.          0.          1.\n   0.          0.        ]]\n[[-0.92471865  0.67836596 -0.26145948  0.          0.          0.\n   0.          0.        ]\n [-0.06134692 -1.47413057  2.42980984  0.          0.          0.\n   1.          0.        ]\n [ 0.18533072  0.67836596 -1.15854926  0.          0.          1.\n   0.          1.        ]\n [-0.43136337  0.67836596 -0.56048941  0.          0.          1.\n   0.          0.        ]\n [-0.67804101  0.67836596  0.03757044  0.          1.          0.\n   0.          1.        ]]\n"
    }
   ],
   "source": [
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print()\n",
    "print(X_train[0:5,:])\n",
    "print()\n",
    "print(X_test[0:5,:])\n",
    "\n",
    "# Normalization\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "featureencoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_indices),\n",
    "        ('cat', categorical_transformer, categorical_indices)        \n",
    "        ]\n",
    "    )\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1qhidLbq7o-5",
    "outputId": "6bfb746c-1ff4-41c9-b0d6-a98fd09a444d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train model...\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 16 epochs took 3 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 9 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 9 epochs took 2 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 15 epochs took 2 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 15 epochs took 2 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 13 epochs took 3 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 3 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 3 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 3 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 3 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 13 epochs took 1 seconds\nconvergence after 14 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 12 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 12 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 14 epochs took 3 seconds\nconvergence after 16 epochs took 4 seconds\nconvergence after 15 epochs took 2 seconds\nconvergence after 15 epochs took 3 seconds\nconvergence after 16 epochs took 2 seconds\nconvergence after 16 epochs took 2 seconds\nconvergence after 14 epochs took 2 seconds\nconvergence after 15 epochs took 1 seconds\nconvergence after 15 epochs took 1 seconds\nconvergence after 12 epochs took 1 seconds\nconvergence after 14 epochs took 1 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 5 epochs took 2 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 3 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 5 epochs took 2 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 3 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 13 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 13 epochs took 1 seconds\nconvergence after 15 epochs took 1 seconds\nconvergence after 15 epochs took 2 seconds\nconvergence after 15 epochs took 2 seconds\nconvergence after 14 epochs took 1 seconds\nconvergence after 12 epochs took 1 seconds\nconvergence after 12 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 5 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 4 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 3 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\nconvergence after 15 epochs took 1 seconds\n...Done.\n"
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "'''\n",
    "classifier = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=6,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None,\n",
    "                       verbose=2, warm_start=False)\n",
    "                       '''\n",
    "classifier = LogisticRegressionCV(Cs= 18, n_jobs= -1, penalty= 'l1', solver= 'saga', verbose= 2, cv=10)\n",
    "# regularized logit with regularization strength chosen by cross-val\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Au2TK_vw7rD-",
    "outputId": "702789a8-4631-4c29-f297-e4b2901f3195"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predictions on training set...\n...Done.\n[0 0 0 ... 0 0 0]\n\n"
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TY_v9uH_CE7"
   },
   "source": [
    "## Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "QS1XrzzE_jQI",
    "outputId": "866a96d2-4180-4bd1-ce54-ba052e75d485"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predictions on test set...\n...Done.\n[0 0 0 ... 1 0 0]\n\n"
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxJCTlz0_2it"
   },
   "source": [
    "## Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6x7p1nyr_3UV",
    "outputId": "8e5b91ba-ca06-4486-d808-37a6aaaa8cf7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "f1-score on train set :  0.7639714113493499\nf1-score on test set :  0.7628865979381443\n"
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "KhDTCeBy__JK",
    "outputId": "72c82d66-d765-437e-e9ef-4ccc80e7183f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion matrix on train set : \n[[191317    756]\n [  1985   4436]]\n\nConfusion matrix on test set : \n[[82009   308]\n [  865  1887]]\n\n"
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report on Test set:\n\n               precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99     82317\n           1       0.86      0.69      0.76      2752\n\n    accuracy                           0.99     85069\n   macro avg       0.92      0.84      0.88     85069\nweighted avg       0.99      0.99      0.99     85069\n\n"
    }
   ],
   "source": [
    "# print classification report\n",
    "print(\"Classification Report on Test set:\\n\\n\", classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tVVDRABv91O"
   },
   "source": [
    "# Train best classifier on all data and use it to make predictions on X_without_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "M14RHUadzE2p",
    "outputId": "abcfcfec-9461-4579-adbd-f23270f984eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\nconvergence after 9 epochs took 2 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 14 epochs took 3 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 3 seconds\nconvergence after 10 epochs took 3 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 13 epochs took 3 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 3 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 7 epochs took 2 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 3 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 4 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 12 epochs took 4 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 10 epochs took 3 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 3 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 11 epochs took 3 seconds\nconvergence after 9 epochs took 2 seconds\nconvergence after 9 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 8 epochs took 2 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 4 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 13 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 10 epochs took 2 seconds\nconvergence after 10 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 12 epochs took 2 seconds\nconvergence after 11 epochs took 2 seconds\nconvergence after 9 epochs took 1 seconds\nconvergence after 11 epochs took 1 seconds\nconvergence after 7 epochs took 1 seconds\nconvergence after 9 epochs took 2 seconds\nconvergence after 6 epochs took 1 seconds\nconvergence after 4 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 8 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 5 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 4 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 0 seconds\nconvergence after 2 epochs took 1 seconds\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.3min finished\nconvergence after 12 epochs took 2 seconds\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegressionCV(Cs=18, class_weight=None, cv=10, dual=False,\n                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n                     max_iter=100, multi_class='auto', n_jobs=-1, penalty='l1',\n                     random_state=None, refit=True, scoring=None, solver='saga',\n                     tol=0.0001, verbose=2)"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "X = np.append(X_train,X_test,axis=0)\n",
    "Y = np.append(Y_train,Y_test)\n",
    "\n",
    "classifier.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tr4CEaPzzbP-",
    "outputId": "f0d1c8ed-be4b-4974-d7b9-f23a49344d9d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction set (without labels) : (31620, 5)\n"
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------\nLooking for outliers in  age\nFound 139 outliers\nDropping outliers...\nDone.\nNumber of lines remaining in dataset :  31481\n\n"
    }
   ],
   "source": [
    "features_list_n = [\"age\"]\n",
    "\n",
    "for f in features_list_n:\n",
    "    print('------------')\n",
    "    print('Looking for outliers in ', f)\n",
    "    mu = data_without_labels[f].mean()\n",
    "    sigma = data_without_labels[f].std()\n",
    "    min_val = mu - 3*sigma\n",
    "    max_val = mu + 3*sigma\n",
    "    is_outlier = (data_without_labels[f]<min_val) | (data_without_labels[f]>max_val)\n",
    "    \n",
    "    if is_outlier.any():\n",
    "        print('Found {} outliers'.format(is_outlier.sum()))\n",
    "        print('Dropping outliers...')\n",
    "        data_without_labels = data_without_labels.loc[~is_outlier,:]\n",
    "        print('Done.')\n",
    "        print('Number of lines remaining in dataset : ', data_without_labels.shape[0])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Convert pandas DataFrames to numpy arrays...\n...Done\n[['UK' 28 0 'Seo' 16]\n ['UK' 22 1 'Direct' 5]\n ['China' 32 1 'Seo' 1]\n ['US' 32 1 'Ads' 6]\n ['China' 25 0 'Seo' 3]]\n"
    }
   ],
   "source": [
    "#data_without_labels['age_page'] = data_without_labels['age'] * data_without_labels['total_pages_visited']\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "features_list = [\"country\", \"age\", \"new_user\", \"source\", \"total_pages_visited\"]\n",
    "X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_without_labels = X_without_labels.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "LoUISfsT0HMR",
    "outputId": "e42dc389-5e77-4e13-ccbc-1fef4aa2c0ca"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Encoding categorical features and standardizing numerical features...\n...Done\n[[-0.30802455 -1.47413057  3.32689962  0.          1.          0.\n   0.          1.        ]\n [-1.04805747  0.67836596  0.03757044  0.          1.          0.\n   1.          0.        ]\n [ 0.18533072  0.67836596 -1.15854926  0.          0.          0.\n   0.          1.        ]\n [ 0.18533072  0.67836596  0.33660037  0.          0.          1.\n   0.          0.        ]\n [-0.67804101 -1.47413057 -0.56048941  0.          0.          0.\n   0.          1.        ]]\n"
    }
   ],
   "source": [
    "# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# CHECK YOU ARE USING X_without_labels\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_without_labels = featureencoder.transform(X_without_labels)\n",
    "print(\"...Done\")\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuWSEHuwEQJ"
   },
   "outputs": [],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "data = {\n",
    "    'converted': classifier.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "Y_predictions.to_csv('./Predictions/conversion_data_test_predictions_LORENZO-Model6.csv', index=False)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqnGkA0jyWaX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}